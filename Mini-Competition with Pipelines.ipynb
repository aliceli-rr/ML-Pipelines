{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Mini-Competition: One-Day Start to Finish Data Science Project\n",
    "\n",
    "## The Task:\n",
    "The task is to complete a full, start-to-finish data science project in one(ish) day, using the \"best practice\" skills we've learned over the past day of the course. \n",
    "\n",
    "## The Data:\n",
    "The data shows real property information, including most recent sales price as of July 2018, for properties located Washington, D.C. The goal is to predict housing prices in DC. It is from [Kaggle](https://www.kaggle.com/christophercorrea/dc-residential-properties/version/7).\n",
    "\n",
    "### Step 1: Exploration\n",
    "- Explore the data and verify it, using tests of course! \n",
    "- At least 1 visualization of the data\n",
    "\n",
    "### Step 2: Model Selection\n",
    "- MUST use gridsearchCV in a pipeline!!\n",
    "\n",
    "### Step 3: Production\n",
    "- Once you've selected your desired model, put it (and the necessary feature engineering) in a pipeline. \n",
    "- Add at least 2 tests, including one for your final output!\n",
    "- Bonus points if your predictor runs as its own python program from command line (rather than in a notebook).\n",
    "\n",
    "Metric used to judge will be MAE (mean absolute error).\n",
    "The team with the lowest MAE on the holdout test set at the end of Wednesday wins!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VPL\\Desktop\\Data Science\\DSR\\DSR_Model_Pipelines_Course\\data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "import ipytest.magics\n",
    "import pytest\n",
    "import numpy as np\n",
    "# set the file name (required)\n",
    "__file__ = '../Mini-Competition with Pipelines.ipynb'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DC_Properties_training.csv', index_col=0, low_memory=False)\n",
    "data = pd.read_csv('holdout_test_data.csv', index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157457, 48)\n",
      "(97091, 48)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.shape)\n",
    "df = df.dropna(subset=['PRICE','SALEDATE','QUADRANT','AYB'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 49)\n",
      "(911, 49)\n",
      "157458     159000.0\n",
      "157460     489590.0\n",
      "157461     495000.0\n",
      "157462     363000.0\n",
      "157463     487000.0\n",
      "157464     369900.0\n",
      "157465     295000.0\n",
      "157468     749000.0\n",
      "157471     673000.0\n",
      "157473     410000.0\n",
      "157474     270000.0\n",
      "157475    1295000.0\n",
      "157476     669900.0\n",
      "157477     225000.0\n",
      "157478     165500.0\n",
      "157480    1170000.0\n",
      "157481     140500.0\n",
      "157482     265000.0\n",
      "157483     335000.0\n",
      "157485     560000.0\n",
      "157486     265000.0\n",
      "157487     160000.0\n",
      "157488     458400.0\n",
      "157491     610000.0\n",
      "157492     501000.0\n",
      "157494     230000.0\n",
      "157496     605000.0\n",
      "157498     187810.0\n",
      "157499     715000.0\n",
      "157500     725000.0\n",
      "            ...    \n",
      "158904      59500.0\n",
      "158905     615000.0\n",
      "158907     640000.0\n",
      "158908     492000.0\n",
      "158910     800000.0\n",
      "158912     689000.0\n",
      "158913     123900.0\n",
      "158915      84000.0\n",
      "158916     700000.0\n",
      "158920     115000.0\n",
      "158923     728700.0\n",
      "158924     769603.0\n",
      "158925     525000.0\n",
      "158926     180000.0\n",
      "158928     121000.0\n",
      "158931      67501.0\n",
      "158932     270000.0\n",
      "158933     700000.0\n",
      "158934     251000.0\n",
      "158937    1552400.0\n",
      "158941     113000.0\n",
      "158942     471000.0\n",
      "158945    4050000.0\n",
      "158947     605927.0\n",
      "158949     660000.0\n",
      "158951     146500.0\n",
      "158952     320000.0\n",
      "158953    1380000.0\n",
      "158954     125000.0\n",
      "158956     900000.0\n",
      "Name: PRICE, Length: 911, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data.head()\n",
    "print(data.shape)\n",
    "\n",
    "data = data.dropna(subset=['PRICE','SALEDATE','QUADRANT','AYB'])\n",
    "print(data.shape)\n",
    "y_test = data['PRICE']\n",
    "print(y_test)\n",
    "x_test = x_test.drop('PRICE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97091, 48)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['PRICE']\n",
    "df = df.drop('PRICE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, target, test_size=0.2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATHRM 0\n",
      "HF_BATHRM 0\n",
      "HEAT 0\n",
      "AC 0\n",
      "NUM_UNITS 39937\n",
      "ROOMS 0\n",
      "BEDRM 0\n",
      "AYB 0\n",
      "YR_RMDL 40065\n",
      "EYB 0\n",
      "STORIES 39970\n",
      "SALEDATE 0\n",
      "QUALIFIED 0\n",
      "SALE_NUM 0\n",
      "GBA 39937\n",
      "BLDG_NUM 0\n",
      "STYLE 39937\n",
      "STRUCT 39937\n",
      "GRADE 39937\n",
      "CNDTN 39937\n",
      "EXTWALL 39937\n",
      "ROOF 39937\n",
      "INTWALL 39937\n",
      "KITCHENS 39938\n",
      "FIREPLACES 0\n",
      "USECODE 0\n",
      "LANDAREA 0\n",
      "GIS_LAST_MOD_DTTM 0\n",
      "SOURCE 0\n",
      "CMPLX_NUM 57154\n",
      "LIVING_GBA 57154\n",
      "FULLADDRESS 40262\n",
      "CITY 40258\n",
      "STATE 40258\n",
      "ZIPCODE 0\n",
      "NATIONALGRID 40258\n",
      "LATITUDE 0\n",
      "LONGITUDE 0\n",
      "ASSESSMENT_NBHD 0\n",
      "ASSESSMENT_SUBNBHD 20016\n",
      "CENSUS_TRACT 0\n",
      "CENSUS_BLOCK 40258\n",
      "WARD 0\n",
      "SQUARE 0\n",
      "X 0\n",
      "Y 0\n",
      "QUADRANT 0\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i,df[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [#'NUM_UNITS',\n",
    "    #'STORIES',\n",
    "    #'GBA',\n",
    "    #'KITCHENS',\n",
    "    #'CMPLX_NUM',\n",
    "    #'LIVING_GBA',\n",
    "    #'SALEDATE', #take year\n",
    "    'AYB',\n",
    "    'CENSUS_TRACT',\n",
    "    'BATHRM',\n",
    "    'HF_BATHRM',\n",
    "    'ROOMS',\n",
    "    'BEDRM',\n",
    "    'SALE_NUM',\n",
    "    'LANDAREA',\n",
    "    'EYB'\n",
    "    ]\n",
    "\n",
    "binary_columns = ['BLDG_NUM',\n",
    "    'QUALIFIED',\n",
    "    'SOURCE'\n",
    "    ]\n",
    "\n",
    "one_hot_encode_column = ['AC',\n",
    "    'QUADRANT'\n",
    "    #,'YR_RMDL'\n",
    "    ]\n",
    "\n",
    "label_encode_column = ['ZIPCODE',\n",
    "    'HEAT',\n",
    "    'USECODE'\n",
    "    #,'STYLE',\n",
    "    #'STRUCT',\n",
    "    #'GRADE',\n",
    "    #'CNDTN', #Definitely do NA-Handling\n",
    "    #'EXTWALL',\n",
    "    # 'ROOF',\n",
    "    # 'INTWALL',\n",
    "    #'ASSESSMENT_NBHD' # too many values\n",
    "    #'WARD' \n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          AYB  CENSUS_TRACT  BATHRM  HF_BATHRM  ROOMS  BEDRM  SALE_NUM  \\\n",
      "index                                                                    \n",
      "0      1910.0        4201.0       4          0      8      4         1   \n",
      "2      1910.0        4201.0       3          1      9      5         3   \n",
      "3      1900.0        4201.0       3          1      8      5         1   \n",
      "5      1913.0        4201.0       3          2     10      5         1   \n",
      "7      1906.0        4201.0       3          1      8      4         1   \n",
      "\n",
      "       LANDAREA   EYB  \n",
      "index                  \n",
      "0          1680  1972  \n",
      "2          1680  1984  \n",
      "3          1680  1984  \n",
      "5          2196  1972  \n",
      "7          1627  1972  \n",
      "       BLDG_NUM QUALIFIED       SOURCE\n",
      "index                                 \n",
      "0             1         Q  Residential\n",
      "2             1         Q  Residential\n",
      "3             1         Q  Residential\n",
      "5             1         Q  Residential\n",
      "7             1         Q  Residential\n",
      "      AC QUADRANT\n",
      "index            \n",
      "0      Y       NW\n",
      "2      Y       NW\n",
      "3      Y       NW\n",
      "5      Y       NW\n",
      "7      Y       NW\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        return x.loc[:,self.columns]\n",
    "\n",
    "numeric_selector = ColumnSelector(numeric_columns)\n",
    "numeric_df = numeric_selector.fit_transform(df)\n",
    "print(numeric_df.head())\n",
    "\n",
    "binary_selector = ColumnSelector(binary_columns)\n",
    "binary_df = binary_selector.fit_transform(df)\n",
    "print(binary_df.head())\n",
    "\n",
    "one_hot_encode_selector = ColumnSelector(one_hot_encode_column)\n",
    "one_hot_encode_df = one_hot_encode_selector.fit_transform(df)\n",
    "print(one_hot_encode_df.head())\n",
    "\n",
    "label_encode_selector = ColumnSelector(label_encode_column)\n",
    "label_encode_df = label_encode_selector.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97091, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.96307917 -0.33063502  2.18942255 ... -0.61636411 -0.14705037\n",
      "   0.22616108]\n",
      " [-0.96307917 -0.33063502  1.16690989 ...  0.81201587 -0.14705037\n",
      "   0.66229189]\n",
      " [-1.23880947 -0.33063502  1.16690989 ... -0.61636411 -0.14705037\n",
      "   0.66229189]\n",
      " ...\n",
      " [-0.19103434 -0.14807817 -0.87811544 ... -0.61636411 -0.583926\n",
      "  -1.0095429 ]\n",
      " [-0.68734888 -0.14807817  0.14439723 ... -0.61636411 -0.59843891\n",
      "  -1.66373912]\n",
      " [ 0.55343746  1.73803838 -0.87811544 ...  0.81201587 -0.64867588\n",
      "  -0.02824856]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_numeric = scaler.fit_transform(numeric_df)\n",
    "print(scaled_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.6.4, pytest-3.3.2, py-1.5.2, pluggy-0.6.0\n",
      "rootdir: C:\\Users\\VPL\\Desktop\\Data Science\\DSR\\DSR_Model_Pipelines_Course, inifile:\n",
      "plugins: palladium-1.2.0\n",
      "collected 1 item\n",
      "\n",
      "..\\Mini-Competition with Pipelines.py .                                  [100%]\n",
      "\n",
      "========================== 1 passed in 0.19 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_standardscaler():\n",
    "    scaler = StandardScaler()\n",
    "    scaled_numeric = scaler.fit_transform(numeric_df)\n",
    "    \n",
    "    assert np.isclose(scaled_numeric.mean(), 0)\n",
    "    assert np.isclose(scaled_numeric.std(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AC', 'QUADRANT'], dtype='object')\n",
      "   0_1  0_2  0_3  0_-1  1_1  1_2  1_3  1_4  1_-1\n",
      "0    1    0    0     0    1    0    0    0     0\n",
      "1    1    0    0     0    1    0    0    0     0\n",
      "2    1    0    0     0    1    0    0    0     0\n",
      "3    1    0    0     0    1    0    0    0     0\n",
      "4    1    0    0     0    1    0    0    0     0\n",
      "5    1    0    0     0    1    0    0    0     0\n",
      "6    1    0    0     0    1    0    0    0     0\n",
      "7    1    0    0     0    1    0    0    0     0\n",
      "8    1    0    0     0    1    0    0    0     0\n",
      "9    1    0    0     0    1    0    0    0     0\n"
     ]
    }
   ],
   "source": [
    "from category_encoders.one_hot import OneHotEncoder\n",
    "one_hot = OneHotEncoder()\n",
    "one_hot_encoded_df = one_hot.fit_transform(one_hot_encode_df.values)\n",
    "print(one_hot_encode_df.columns)\n",
    "print(one_hot_encoded_df.iloc[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.6.4, pytest-3.3.2, py-1.5.2, pluggy-0.6.0\n",
      "rootdir: C:\\Users\\VPL\\Desktop\\Data Science\\DSR\\DSR_Model_Pipelines_Course, inifile:\n",
      "plugins: palladium-1.2.0\n",
      "collected 1 item\n",
      "\n",
      "..\\Mini-Competition with Pipelines.py .                                  [100%]\n",
      "\n",
      "============================== warnings summary ===============================\n",
      "None\n",
      "  Module already imported so cannot be rewritten: palladium\n",
      "\n",
      "-- Docs: http://doc.pytest.org/en/latest/warnings.html\n",
      "==================== 1 passed, 1 warnings in 0.28 seconds =====================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_OneHotEncoder():\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    one_hot_encoded_df = one_hot.fit_transform(one_hot_encode_df.values)\n",
    "    \n",
    "    # check for data leakage\n",
    "    assert one_hot_encoded_df.shape[0] == one_hot_encode_df.shape[0]\n",
    "    \n",
    "    # check that all values have been converted into integers\n",
    "    assert one_hot_encoded_df.dtypes.all() == 'int32'\n",
    "    \n",
    "    # check that only 0s and 1s exist in the new matrix\n",
    "    assert ((one_hot_encoded_df.values ==0) | (one_hot_encoded_df.values ==1)).all()\n",
    "    \n",
    "    # check that a dummy column has been made for each potential category \n",
    "    assert one_hot_encoded_df.shape[1] == len(set(one_hot_encoded_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ZIPCODE', 'HEAT', 'USECODE'], dtype='object')\n",
      "         0  1   2\n",
      "0  20009.0  1  24\n",
      "1  20009.0  2  24\n",
      "2  20009.0  2  24\n",
      "3  20009.0  2  11\n",
      "4  20009.0  2  24\n",
      "5  20009.0  1  24\n",
      "6  20009.0  1  24\n",
      "7  20009.0  1  11\n",
      "8  20009.0  2  24\n",
      "9  20009.0  2  13\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97091 entries, 0 to 97090\n",
      "Data columns (total 3 columns):\n",
      "0    97091 non-null float64\n",
      "1    97091 non-null int32\n",
      "2    97091 non-null int64\n",
      "dtypes: float64(1), int32(1), int64(1)\n",
      "memory usage: 1.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "label_encoded_df = encoder.fit_transform(label_encode_df.values)\n",
    "print(label_encode_df.columns)\n",
    "print(label_encoded_df.iloc[:10,:])\n",
    "print(label_encoded_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = list(x_train.columns)\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "\n",
    "# process the numeric and categorical columns.\n",
    "# then, join them all together.\n",
    "\n",
    "processing_pipeline = make_pipeline(\n",
    "    # If using make_union, then we HAVE to first select all the columns we will pull from.\n",
    "    ColumnSelector(all_columns),\n",
    "    make_union(\n",
    "        # First, we select and 'hold out' the binary variables, as we wont do any further work to them.\n",
    "        make_pipeline(\n",
    "            ColumnSelector(binary_columns),\n",
    "            OrdinalEncoder()\n",
    "        ),\n",
    "        # Pipeline for numeric features\n",
    "        make_pipeline(\n",
    "            ColumnSelector(numeric_columns),\n",
    "            StandardScaler()\n",
    "        ),\n",
    "        # Pipeline for label encoded features\n",
    "        make_pipeline(\n",
    "            ColumnSelector(label_encode_column),\n",
    "            OrdinalEncoder()\n",
    "        ),\n",
    "        \n",
    "        # Pipeline for one-hot-encoded features\n",
    "        make_pipeline(\n",
    "            ColumnSelector(one_hot_encode_column),\n",
    "            OneHotEncoder()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = processing_pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.6.4, pytest-3.3.2, py-1.5.2, pluggy-0.6.0\n",
      "rootdir: C:\\Users\\VPL\\Desktop\\Data Science\\DSR\\DSR_Model_Pipelines_Course, inifile:\n",
      "plugins: palladium-1.2.0\n",
      "collected 1 item\n",
      "\n",
      "..\\Mini-Competition with Pipelines.py .                                  [100%]\n",
      "\n",
      "============================== warnings summary ===============================\n",
      "None\n",
      "  Module already imported so cannot be rewritten: palladium\n",
      "\n",
      "-- Docs: http://doc.pytest.org/en/latest/warnings.html\n",
      "==================== 1 passed, 1 warnings in 0.64 seconds =====================\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_processingpipeline():\n",
    "    # remember, this first pipeline only acts on the features, not the target.\n",
    "    processed = processing_pipeline.fit_transform(x_train)\n",
    "    \n",
    "    # check for data leakage\n",
    "    assert x_train.shape[0] == processed.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148912.41342407095\n",
      "0.9620321249262769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "finalpipeline = (make_pipeline(processing_pipeline, RandomForestRegressor(n_estimators=100,max_depth=100)))\n",
    "finalpipeline.fit(x_train,y_train)\n",
    "y_pred = finalpipeline.predict(x_test)\n",
    "\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "finalpipeline = (make_pipeline(processing_pipeline, RandomForestRegressor(n_estimators=500,max_depth=100)))\n",
    "finalpipeline.fit(x_train,y_train)\n",
    "y_pred = finalpipeline.predict(x_test)\n",
    "\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('columnselector', ColumnSelector(columns=['BATHRM', 'HF_BATHRM', 'HEAT', 'AC', 'NUM_UNITS', 'ROOMS', 'BEDRM', 'AYB', 'YR_RMDL', 'EYB', 'STORIES', 'SALEDATE', 'QUALIFIED', 'SALE_NUM', 'GBA', 'BLDG_NUM', 'STYLE', 'STRUCT', 'GRADE', 'CNDTN', 'EXTWA...e=1, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalpipeline = (make_pipeline(processing_pipeline, GradientBoostingRegressor(random_state=1, \n",
    "                                                                              n_estimators=100,\n",
    "                                                                            learning_rate=0.01)))\n",
    "# Fitting the pipeline\n",
    "finalpipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = finalpipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166834.11284511906\n",
      "0.9915624964128249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradientboostingregressor__n_estimators': [500], 'gradientboostingregressor__learning_rate': [0.001, 0.01]}\n",
      "Grid search\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('columnselector', ColumnSelector(columns=['BATHRM', 'HF_BATHRM', 'HEAT', 'AC', 'NUM_UNITS', 'ROOMS', 'BEDRM', 'AYB', 'YR_RMDL', 'EYB', 'STORIES', 'SALEDATE', 'QUALIFIED', 'SALE_NUM', 'GBA', 'BLDG_NUM', 'STYLE', 'STRUCT', 'GRADE', 'CNDTN', 'EXTWA...e=1, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'gradientboostingregressor__n_estimators': [500], 'gradientboostingregressor__learning_rate': [0.001, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trees in gradient Boosting\n",
    "n_estimators = [500]\n",
    "# Number of features to consider at every split\n",
    "learning_rate = [0.001, 0.01]\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'gradientboostingregressor__n_estimators': n_estimators,\n",
    "               'gradientboostingregressor__learning_rate': learning_rate\n",
    "              }\n",
    "\n",
    "print(random_grid)\n",
    "\n",
    "print(\"Grid search\")\n",
    "print('\\n')\n",
    "\n",
    "params = random_grid\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "clf = GridSearchCV(finalpipeline, params, n_jobs=1, verbose=True, scoring=scoring)\n",
    "clf.fit(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_gradientboostingregressor__learning_rate</th>\n",
       "      <th>param_gradientboostingregressor__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.309447</td>\n",
       "      <td>0.385606</td>\n",
       "      <td>-808855.848041</td>\n",
       "      <td>-497338.735039</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>{'gradientboostingregressor__learning_rate': 0...</td>\n",
       "      <td>1</td>\n",
       "      <td>-589865.845407</td>\n",
       "      <td>-667205.365987</td>\n",
       "      <td>-439553.029333</td>\n",
       "      <td>-6.437420e+05</td>\n",
       "      <td>-1.397167e+06</td>\n",
       "      <td>-181068.870723</td>\n",
       "      <td>2.652448</td>\n",
       "      <td>0.032918</td>\n",
       "      <td>420494.072129</td>\n",
       "      <td>223841.615229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.286955</td>\n",
       "      <td>0.397253</td>\n",
       "      <td>-867309.210513</td>\n",
       "      <td>-763347.895811</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>{'gradientboostingregressor__learning_rate': 0...</td>\n",
       "      <td>2</td>\n",
       "      <td>-441904.314108</td>\n",
       "      <td>-981308.901312</td>\n",
       "      <td>-710971.535630</td>\n",
       "      <td>-1.014619e+06</td>\n",
       "      <td>-1.449070e+06</td>\n",
       "      <td>-294115.405980</td>\n",
       "      <td>2.186811</td>\n",
       "      <td>0.032735</td>\n",
       "      <td>425774.303383</td>\n",
       "      <td>332076.039621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "1      28.309447         0.385606   -808855.848041    -497338.735039   \n",
       "0      25.286955         0.397253   -867309.210513    -763347.895811   \n",
       "\n",
       "  param_gradientboostingregressor__learning_rate  \\\n",
       "1                                           0.01   \n",
       "0                                          0.001   \n",
       "\n",
       "  param_gradientboostingregressor__n_estimators  \\\n",
       "1                                           500   \n",
       "0                                           500   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "1  {'gradientboostingregressor__learning_rate': 0...                1   \n",
       "0  {'gradientboostingregressor__learning_rate': 0...                2   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "1     -589865.845407      -667205.365987     -439553.029333   \n",
       "0     -441904.314108      -981308.901312     -710971.535630   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "1       -6.437420e+05      -1.397167e+06      -181068.870723      2.652448   \n",
       "0       -1.014619e+06      -1.449070e+06      -294115.405980      2.186811   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "1        0.032918   420494.072129    223841.615229  \n",
       "0        0.032735   425774.303383    332076.039621  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params = (clf.cv_results_)\n",
    "all_params = pd.DataFrame(all_params)\n",
    "all_params.sort_values('rank_test_score').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compare_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Desktop\\Data Science\\DSR\\DSR_Model_Pipelines_Course\\Mini-Competition with Pipelines.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgridsearch_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absenteeism_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'compare_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "gridsearch_predictions = compare_predictions(df, target, clf, mean_absenteeism_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
